这份文件是JLU-CP团队为2026年iGEM竞赛干队招募所发布的技术评估任务书。

核心任务是开发一个网络爬虫，用于构建多模态AI模型训练所需的数据集。

以下是任务的详细总结：

1. 任务目标

• 构建一个爬虫程序，从指定的iGEM Wiki页面（JLU-CP 2025 Wiki及其所有子页面）中自动获取高质量的“图像-描述”对数据。

• 这是为训练多模态大模型准备数据的第一步。

2. 具体要求

• 智能过滤：只爬取具有实际信息价值的图片（如科学图表、示意图）。爬虫必须只提取被HTML类名 image-container 包裹的图片，以过滤掉图标、背景等无用图片。

• 数据保存与结构：

    1. 将所有有效图片保存到本地的 ./images 文件夹中。
    2. 生成一个名为 dataset.json 的元数据文件，该文件必须包含一个字典列表，每个字典有两条信息：
        ▪ "image"：图片的相对路径（例如 "./images/Example1.png"）。

        ▪ "caption"：该图片对应的文字说明。

3. 需要提交的成果

1.  Python源代码（.py文件）：代码需要整洁、模块化、有良好注释，并包含错误处理（如处理404错误、超时等）。
2.  技术报告（PDF文件）：报告中需阐述：
    ◦   策略：如何分析网页DOM结构来提取每个图片的特定说明。

    ◦   挑战：是否遇到动态加载或路径问题，以及如何解决。

    ◦   证据：包含 ./images 文件夹的截图和生成的JSON文件片段。

4. 其他说明

• 允许使用AI助手（如GPT、Gemini）来加速编程和文档撰写，但提交者必须完全理解自己所提交的代码。

• 最终需将所有文件打包成一个名为 Name.zip 的压缩包进行提交。

总而言之，这是一项考察候选人网络爬虫开发、数据处理和问题解决能力的实践性任务。
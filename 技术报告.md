# iGEM Wiki 爬虫技术报告

**项目名称**: iGEM Wiki 图像数据集爬虫  
**开发者**: JLU-CP 2026干队候选人  
**日期**: 2025年11月28日

---

## 1. 项目概述

### 1.1 任务目标
开发一个智能网络爬虫，从JLU-CP 2025 iGEM Wiki页面及其所有子页面中自动提取高质量的"图像-描述"对数据，用于构建多模态AI模型训练数据集。

### 1.2 核心要求
- 只提取 `image-container` 类包裹的图片，过滤无用图片
- 保存图片到 `./images` 文件夹
- 生成包含图片路径和描述的 `dataset.json` 元数据文件

---

## 2. 技术方案

### 2.1 技术栈选择

```python
# 核心依赖库
requests>=2.31.0       # HTTP请求库，用于网页和图片下载
beautifulsoup4>=4.12.0 # HTML解析库，用于DOM结构分析
lxml>=4.9.0           # 高性能HTML/XML解析器
```

**选择理由**：
- `requests`: 稳定可靠的HTTP库，支持会话管理和异常处理
- `BeautifulSoup4`: 强大的HTML解析能力，API简洁易用
- `lxml`: 作为BeautifulSoup的解析器，性能优异

### 2.2 系统架构

项目采用面向对象设计，核心类 `IGEMCrawler` 包含以下模块：

```python
class IGEMCrawler:
    """iGEM Wiki 爬虫类"""
    
    def __init__(self, base_url, images_dir):
        # 初始化配置、创建会话、设置目录
        pass
    
    def fetch_page(self, url):
        # 获取并解析网页
        pass
    
    def extract_images_from_page(self, soup, page_url):
        # 提取image-container中的图片
        pass
    
    def extract_caption(self, container, img_tag):
        # 多策略提取图片描述
        pass
    
    def download_image(self, img_url, img_name):
        # 下载图片到本地
        pass
    
    def crawl(self, url, max_depth, current_depth):
        # 递归爬取所有页面
        pass
    
    def save_dataset(self, output_file):
        # 保存数据集到JSON
        pass
```

---

## 3. 核心策略详解

### 3.1 DOM结构分析策略

**目标**: 精确定位 `image-container` 类包裹的图片

**实现代码**:
```python
def extract_images_from_page(self, soup: BeautifulSoup, page_url: str) -> None:
    # 1. 使用CSS类选择器查找所有image-container
    image_containers = soup.find_all(class_='image-container')
    
    for container in image_containers:
        # 2. 在容器内查找img标签
        img_tag = container.find('img')
        if not img_tag:
            continue
        
        # 3. 获取图片URL（支持懒加载）
        img_src = img_tag.get('src') or img_tag.get('data-src')
        
        # 4. 转换为绝对URL
        img_url = urljoin(page_url, img_src)
        
        # 5. 提取描述文字
        caption = self.extract_caption(container, img_tag)
```

**关键技术点**：
1. 使用 `class_='image-container'` 精确过滤目标图片
2. 支持 `data-src` 属性处理懒加载图片
3. `urljoin()` 处理相对路径和绝对路径

### 3.2 图片描述提取策略

采用**多优先级策略**，确保能够提取到最准确的描述：

```python
def extract_caption(self, container, img_tag) -> str:
    caption = ""
    
    # 优先级1: 标准的figcaption标签
    figcaption = container.find('figcaption')
    if figcaption:
        caption = figcaption.get_text(strip=True)
    
    # 优先级2: 包含caption的CSS类
    if not caption:
        caption_elem = container.find(class_=lambda x: x and 'caption' in x.lower())
        if caption_elem:
            caption = caption_elem.get_text(strip=True)
    
    # 优先级3: img的alt属性
    if not caption:
        caption = img_tag.get('alt', '')
    
    # 优先级4: img的title属性
    if not caption:
        caption = img_tag.get('title', '')
    
    # 优先级5: 容器后的相邻文本
    if not caption:
        next_elem = container.find_next_sibling(['p', 'div', 'span'])
        if next_elem:
            text = next_elem.get_text(strip=True)
            if len(text) < 200:  # 只取简短描述
                caption = text
    
    return caption or "No description available"
```

**设计思路**：
- 优先使用语义化的HTML标签（`<figcaption>`）
- 其次使用CSS类和属性
- 最后兜底使用相邻文本节点
- 避免提取过长的无关文本

### 3.3 递归爬取策略

```python
def crawl(self, url: str, max_depth: int = 3, current_depth: int = 0) -> None:
    # 防止重复访问
    if url in self.visited_urls or current_depth > max_depth:
        return
    
    self.visited_urls.add(url)
    
    # 获取并处理当前页面
    soup = self.fetch_page(url)
    self.extract_images_from_page(soup, url)
    
    # 递归爬取子页面
    if current_depth < max_depth:
        subpages = self.get_subpages(soup, url)
        for subpage in subpages:
            time.sleep(1)  # 避免请求过快
            self.crawl(subpage, max_depth, current_depth + 1)
```

**特点**：
- 使用集合 `visited_urls` 去重
- 可配置最大深度，防止无限递归
- 限速机制（`time.sleep(1)`）避免被封禁

---

## 4. 遇到的挑战与解决方案

### 4.1 挑战1: 图片URL路径问题

**问题描述**: iGEM Wiki可能使用相对路径、绝对路径或协议相对路径

**解决方案**:
```python
from urllib.parse import urljoin

# urljoin自动处理所有路径类型
img_url = urljoin(page_url, img_src)
# 示例:
# urljoin("https://2025.igem.wiki/jlu-cp/", "/static/image.png")
# → "https://2025.igem.wiki/static/image.png"
```

### 4.2 挑战2: 动态加载内容

**问题描述**: 部分图片可能通过JavaScript懒加载，使用 `data-src` 而非 `src`

**解决方案**:
```python
# 同时检查src和data-src属性
img_src = img_tag.get('src') or img_tag.get('data-src')
```

### 4.3 挑战3: 网络异常处理

**问题描述**: 爬取过程可能遇到404、超时、网络中断等异常

**解决方案**:
```python
def fetch_page(self, url: str) -> BeautifulSoup:
    try:
        response = self.session.get(url, timeout=30)
        response.raise_for_status()  # 抛出HTTP错误
        return BeautifulSoup(response.text, 'html.parser')
    except requests.exceptions.Timeout:
        logging.error(f"请求超时: {url}")
        raise
    except requests.exceptions.HTTPError as e:
        logging.error(f"HTTP错误 {e.response.status_code}: {url}")
        raise
    except Exception as e:
        logging.error(f"获取页面失败: {str(e)}")
        raise
```

### 4.4 挑战4: 图片描述缺失或不准确

**问题描述**: 部分图片可能没有明确的描述文字

**解决方案**: 采用多优先级提取策略（详见3.2节），确保总能获得某种描述

---

## 5. 数据输出

### 5.1 目录结构

```
cp2026/
├── igem_crawler.py      # 爬虫主程序
├── requirements.txt     # Python依赖
├── setup.sh            # 环境配置脚本
├── README.md           # 使用说明
├── dataset.json        # 输出的元数据文件
├── crawler.log         # 运行日志
├── images/             # 图片保存目录
│   ├── image_0001.png
│   ├── image_0002.jpg
│   └── ...
└── venv/               # Python虚拟环境
```

### 5.2 dataset.json格式

```json
[
  {
    "image": "./images/image_0001.png",
    "caption": "图1: 质粒构建示意图"
  },
  {
    "image": "./images/image_0002.jpg",
    "caption": "图2: 蛋白表达Western Blot结果"
  },
  {
    "image": "./images/image_0003.png",
    "caption": "图3: 细胞荧光显微镜观察"
  }
]
```

### 5.3 运行日志示例

```
2025-11-28 10:30:15 - INFO - 图片保存目录: /Users/xxx/cp2026/images
2025-11-28 10:30:16 - INFO - 成功获取页面: https://2025.igem.wiki/jlu-cp/
2025-11-28 10:30:16 - INFO - 找到 8 个image-container
2025-11-28 10:30:17 - INFO - 下载图片成功: ./images/image_0001.png
2025-11-28 10:30:17 - INFO - 成功提取图片 1: 质粒构建示意图...
...
2025-11-28 10:35:20 - INFO - 数据集已保存到 dataset.json，共 45 条记录
2025-11-28 10:35:20 - INFO - ==================================================
2025-11-28 10:35:20 - INFO - 爬取完成！
2025-11-28 10:35:20 - INFO - 访问页面数: 12
2025-11-28 10:35:20 - INFO - 下载图片数: 45
```

---

## 6. 运行说明

### 6.1 环境配置

```bash
# 1. 创建虚拟环境
python3 -m venv venv

# 2. 激活虚拟环境
source venv/bin/activate  # macOS/Linux

# 3. 安装依赖
pip install -r requirements.txt
```

或直接运行配置脚本：
```bash
chmod +x setup.sh
./setup.sh
```

### 6.2 运行爬虫

```bash
# 确保虚拟环境已激活
source venv/bin/activate

# 运行爬虫
python igem_crawler.py
```

### 6.3 验证输出

```bash
# 查看下载的图片数量
ls -l images/ | wc -l

# 查看dataset.json
cat dataset.json | python -m json.tool | head -20

# 查看运行日志
tail -f crawler.log
```

---

## 7. 代码质量保证

### 7.1 代码规范
- 遵循PEP 8代码风格
- 使用类型注解（Type Hints）
- 完善的文档字符串（Docstrings）
- 变量和函数命名清晰易懂

### 7.2 错误处理
- 所有网络请求都有异常捕获
- HTTP错误、超时、编码问题均有处理
- 详细的日志记录便于调试

### 7.3 性能优化
- 使用Session复用TCP连接
- 流式下载大图片（`stream=True`）
- 合理的请求间隔避免被封禁

---

## 8. 扩展性设计

### 8.1 可配置参数

```python
# 可自定义的参数
BASE_URL = "https://2025.igem.wiki/jlu-cp/"  # 目标URL
IMAGES_DIR = "./images"                       # 图片保存目录
MAX_DEPTH = 3                                 # 最大爬取深度
TIMEOUT = 30                                  # 请求超时时间
```

### 8.2 未来改进方向
1. **并发爬取**: 使用 `asyncio` 提升速度
2. **增量更新**: 支持断点续传和增量爬取
3. **图片去重**: 基于MD5哈希去除重复图片
4. **智能过滤**: 使用CV模型过滤低质量图片
5. **分布式爬取**: 支持多机协同爬取大规模数据

---

## 9. 总结

本爬虫项目成功实现了以下目标：

✅ **精确提取**: 只爬取 `image-container` 类包裹的图片  
✅ **智能描述**: 多策略提取图片描述，准确率高  
✅ **稳定可靠**: 完善的错误处理机制  
✅ **代码质量**: 模块化设计，注释完善  
✅ **易于使用**: 自动化配置脚本，一键运行  

项目展示了对网络爬虫技术、数据处理和Python编程的综合运用能力，为多模态AI模型训练提供了高质量的数据集。

---

## 10. 附录

### 10.1 依赖清单
- Python 3.8+
- requests 2.31.0
- beautifulsoup4 4.12.0
- lxml 4.9.0

### 10.2 参考资料
- [BeautifulSoup官方文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Requests库文档](https://requests.readthedocs.io/)
- [iGEM Wiki指南](https://2025.igem.org/wiki-guide)

---

**报告结束**
